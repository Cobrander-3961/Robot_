This work constructs a full-stack intelligent mobile robot based on the RKDX5 embedded platform and the ROS 2 Foxy system. It achieves real-time SLAM mapping and dynamic path planning with centimeter-level accuracy in indoor environments through a single-line LiDAR (RPLIDAR A1) (positioning accuracy Â±2cm), and simultaneously deploys the YOLOv8-Tiny lightweight model on the embedded platform to perform real-time object detection at 30fps, capable of accurately identifying and tracking dynamic obstacles such as humans and furniture. The innovative design of the quadruped hub motor direct drive chassis structure is driven by the STM32G431 microcontroller through a high-frequency FOC (Field Oriented Control) algorithm, and combines MPU6050 IMU sensor data for Kalman filter fusion, achieving millisecond-level response (<50ms) self-balancing adjustment. The four-degree-of-freedom SCARA mechanical arm uses the MoveIt 2 framework for inverse kinematics solution and obstacle avoidance trajectory planning, and the end effector can complete precise grasping tasks with a 500g load. The multimodal interaction system includes the ASRPRO chip for basic voice command parsing with a recognition rate of 98% (such as "forward", "left turn"), and the local deployment of the Xiaozhi voice assistant processes natural language conversations. The dual 1-inch LCD displays respectively render anthropomorphic expression animations and real-time system dashboards (CPU temperature / environmental humidity / network latency / task queue), and support remote monitoring and control from mobile devices through the HC-05 Bluetooth transparent transmission module.